<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>B.O.S. v1</title>
  <link
    href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&display=swap"
    rel="stylesheet"
  />
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    html, body {
      width: 100%; height: 100%;
      background: #000; color: #fff;
      font-family: 'Orbitron', sans-serif;
      overflow: hidden;
    }
    /* BOOT SCREEN */
    #boot-screen {
      position: fixed; inset: 0;
      background: #000;
      display: flex; flex-direction: column;
      align-items: center; justify-content: center;
      z-index: 1000;
      opacity: 1;
      transition: opacity 1s ease-out;
    }
    #boot-screen.fade-out { opacity: 0; }
    #boot-screen img {
      width: 60vw; max-width: 600px;
      height: auto; display: block;
    }
    #boot-text {
      margin-top: 1rem; font-size: 1.5rem; color: #fff;
    }

    /* MAIN APP (hidden until boot done) */
    #main-content {
      position: relative;
      display: none; /* will switch to flex */
      flex-direction: column;
      align-items: center;
      justify-content: space-between;
      height: 100%; width: 100%;
      padding: 2rem 0;
      opacity: 0;
      transition: opacity 1s ease-in;
    }
    #main-content.fade-in {
      display: flex; opacity: 1;
    }

    /* HEADER */
    h1 {
      font-size: 3rem;
      color: #fff;
      text-shadow: 0 0 12px #fff;
    }

    /* VISUALIZER */
    #visualizer {
      width: 140px; height: 140px;
      border-radius: 50%;
      overflow: hidden;
      transition: transform 0.2s ease-out;
      margin-bottom: 1rem;
    }
    #visualizer.speaking {
      animation: heartbeat 1s ease-in-out infinite;
    }
    @keyframes heartbeat {
      0%,40%,100% { transform: scale(1); }
      10% { transform: scale(1.2); }
      30% { transform: scale(1.15); }
    }

    /* CHAT LOG */
    #chat-log {
      width: 80%; max-width: 600px;
      background: #111;
      border: 1px solid #333;
      border-radius: 6px;
      padding: 1rem;
      flex: 1;
      overflow-y: auto;
      margin-bottom: 1rem;
    }
    #chat-log div { margin-bottom: .5rem; }
    .you { color: #0af; }
    .bos { color: #fff; }

    /* INPUT CONTROLS */
    #controls {
      width: 80%; max-width: 600px;
      display: flex; margin-bottom: 1rem;
    }
    #user-input {
      flex: 1;
      padding: .75em;
      border: none;
      border-radius: 6px 0 0 6px;
      background: #111;
      color: #fff;
      outline: none;
      font-size: 1em;
    }
    #send-btn {
      padding: 0 .75em;
      background: #fff;
      color: #000;
      border: none;
      border-radius: 0 6px 6px 0;
      cursor: pointer;
      font-size: 1em;
      transition: background 0.2s ease;
    }
    #send-btn:hover { background: #ddd; }

    /* RECORD & CONVERSATION BUTTONS */
    #record-btn,
    #conversation-btn {
      margin-left: .5rem;
      padding: 0 .75em;
      background: #222;
      color: #fff;
      border: none;
      border-radius: 6px;
      cursor: pointer;
      font-size: 1em;
      transition: background 0.2s ease;
    }
    #record-btn:hover,
    #conversation-btn:hover { background: #333; }
  </style>
</head>
<body>

  <!-- BOOT SCREEN -->
  <div id="boot-screen">
    <img src="{{ url_for('static', filename='boot.gif') }}" alt="B.O.S. Boot Sequence" />
    <div id="boot-text">Initializing B.O.S...</div>
  </div>

  <!-- MAIN APP -->
  <div id="main-content">
    <h1>B.O.S.</h1>

    <img id="visualizer"
         src="{{ url_for('static', filename='orb.gif') }}"
         alt="BOS speaking visualizer" />

    <div id="chat-log"></div>

    <div id="controls">
      <input id="user-input" type="text" placeholder="Type a messageâ€¦" />
      <button id="send-btn">Send</button>
      <button id="record-btn">ðŸŽ¤ Record</button>
      <button id="conversation-btn">Conversation</button>
    </div>

    <audio id="tts-player" style="display:none;"></audio>
  </div>

  <script>
    // BOOT â†’ MAIN
    const boot = document.getElementById('boot-screen');
    const main = document.getElementById('main-content');
    setTimeout(() => {
      boot.classList.add('fade-out');
      boot.addEventListener('transitionend', () => {
        boot.style.display = 'none';
        main.classList.add('fade-in');
      }, { once: true });
    }, 3000);

    // CHAT & TTS
    const chatLog = document.getElementById('chat-log');
    const input   = document.getElementById('user-input');
    const btn     = document.getElementById('send-btn');
    const orb     = document.getElementById('visualizer');
    const tts     = document.getElementById('tts-player');

    tts.addEventListener('play',  () => orb.classList.add('speaking'));
    tts.addEventListener('ended', () => orb.classList.remove('speaking'));

    async function sendMessage(txt) {
      let text = typeof txt === 'string' ? txt.trim() : input.value.trim();
      if (!text) return;
      chatLog.innerHTML += `<div class="you"><strong>You:</strong> ${text}</div>`;
      chatLog.scrollTop = chatLog.scrollHeight;
      input.value = '';
      let res = await fetch('/api/message', {
        method: 'POST',
        headers: { 'Content-Type':'application/json' },
        body: JSON.stringify({ text })
      });
      const { reply } = await res.json();
      chatLog.innerHTML += `<div class="bos"><strong>BOS:</strong> ${reply}</div>`;
      chatLog.scrollTop = chatLog.scrollHeight;
      res = await fetch('/api/speak', {
        method: 'POST',
        headers: { 'Content-Type':'application/json' },
        body: JSON.stringify({ text: reply })
      });
      const { url } = await res.json();
      tts.src = url; tts.play();
    }

    btn.addEventListener('click', sendMessage);
    input.addEventListener('keydown', e => {
      if (e.key === 'Enter') sendMessage();
    });

    // RECORD / STOP â†’ WHISPER
    const recordBtn = document.getElementById('record-btn');
    let mediaRecorder, audioChunks = [], isRecording = false;

    recordBtn.addEventListener('click', async () => {
      if (!isRecording) {
        // pick MP3 if supported, else WebM/Opus
        const useMp3 = MediaRecorder.isTypeSupported('audio/mpeg');
        const mimeType = useMp3 ? 'audio/mpeg' : 'audio/webm;codecs=opus';
        console.log('â–¶ï¸ Recording with', mimeType);

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream, { mimeType });
        audioChunks = [];

        mediaRecorder.addEventListener('dataavailable', e => {
          console.log('ðŸ—‚ Chunk:', e.data.type, e.data.size, 'bytes');
          audioChunks.push(e.data);
        });

        mediaRecorder.addEventListener('stop', async () => {
          // wrap into a File so Whisper sees correct type
          const blob = new Blob(audioChunks, { type: mimeType });
          console.log('â¹ï¸ Raw blob.type:', blob.type);
          const ext = useMp3 ? 'mp3' : 'webm';
          const file = new File([blob], `voice.${ext}`, { type: blob.type });

          const form = new FormData();
          form.append('file', file);

          const url = `${window.location.origin}/api/transcribe`;
          console.log('ðŸ“¤ Sending file to', url);

          try {
            const res = await fetch(url, { method: 'POST', body: form });
            console.log('ðŸ–¥ï¸ Whisper status:', res.status);
            const json = await res.json();
            console.log('ðŸ”¤ Whisper says:', json);
            if (json.text) input.value = json.text;
          } catch (err) {
            console.error('âŒ Whisper error:', err);
          }
        });

        mediaRecorder.start();
        recordBtn.textContent = 'â¹ Stop';
        isRecording = true;

      } else {
        console.log('â¹ï¸ Stopping recording');
        mediaRecorder.stop();
        recordBtn.textContent = 'ðŸŽ¤ Record';
        isRecording = false;
      }
    });

    // CONVERSATION MODE
    const convoBtn = document.getElementById('conversation-btn');
    const SpeechRec = window.SpeechRecognition || window.webkitSpeechRecognition;
 codex/add-conversation-mode-with-speechrecognition-qbrorf
    const MR       = window.MediaRecorder || window.WebKitMediaRecorder;

 const MR       = window.MediaRecorder || window.WebKitMediaRecorder;
 main

    let recognition;
    let convoRecorder, convoStream, convoChunks = [], convoTimer;
    let isConversing = false;

    const CHUNK_MS = 5000; // 5 sec per segment

    function startChunk() {
      convoRecorder.start();
      convoTimer = setTimeout(() => {
        if (convoRecorder.state === 'recording') convoRecorder.stop();
      }, CHUNK_MS);
    }

    async function startFallback() {
      const useMp3  = MR && MR.isTypeSupported && MR.isTypeSupported('audio/mpeg');
      const mime    = useMp3 ? 'audio/mpeg' : 'audio/webm;codecs=opus';
      convoStream   = await navigator.mediaDevices.getUserMedia({ audio: true });
      convoRecorder = new MR(convoStream, { mimeType: mime });
      convoChunks   = [];

      convoRecorder.addEventListener('dataavailable', e => convoChunks.push(e.data));
      convoRecorder.addEventListener('stop', async () => {
        const blob = new Blob(convoChunks, { type: mime });
        const ext  = useMp3 ? 'mp3' : 'webm';
        const file = new File([blob], `convo.${ext}`, { type: blob.type });
        const form = new FormData();
        form.append('file', file);
        try {
          const res  = await fetch('/api/transcribe', { method: 'POST', body: form });
          const json = await res.json();
          if (json.text) sendMessage(json.text);
        } catch (err) {
          console.error('âŒ Convo transcribe error:', err);
        }
        convoChunks = [];
        if (isConversing) startChunk();
      });

      startChunk();
    }

    function stopFallback() {
      clearTimeout(convoTimer);
      if (convoRecorder && convoRecorder.state === 'recording') convoRecorder.stop();
      if (convoStream) convoStream.getTracks().forEach(t => t.stop());
    }

    if (SpeechRec) {
      recognition = new SpeechRec();
      recognition.continuous = true;
      recognition.interimResults = false;

      recognition.addEventListener('result', e => {
codex/add-conversation-mode-with-speechrecognition-qbrorf
        const transcript = e.results[e.resultIndex][0].transcript;
        const clean = transcript.trim();
        if (!clean || clean === '.') return;
        sendMessage(clean);

        const transcript = Array.from(e.results)
          .map(r => r[0].transcript)
          .join('');
        sendMessage(transcript);
 main
      });

      recognition.addEventListener('end', () => {
        if (isConversing) recognition.start();
      });
    }

 codex/add-conversation-mode-with-speechrecognition-qbrorf
    if (!SpeechRec && !(MR && navigator.mediaDevices?.getUserMedia)) {
      convoBtn.disabled = true;
      convoBtn.title = 'Speech recognition not supported';
    }


main
    convoBtn.addEventListener('click', async () => {
      if (!isConversing) {
        isConversing = true;
        convoBtn.textContent = 'Stop Conversation';
        if (recognition) {
          recognition.start();
        } else if (MR && navigator.mediaDevices?.getUserMedia) {
          await startFallback();
        } else {
          alert('Speech recognition not supported in this browser.');
          isConversing = false;
          convoBtn.textContent = 'Conversation';
        }
      } else {
        isConversing = false;
        convoBtn.textContent = 'Conversation';
        if (recognition) recognition.stop();
        else stopFallback();
      }
    });
  </script>
</body>
</html>
codex/add-conversation-mode-with-speechrecognition-qbrorf
</html>
 main
